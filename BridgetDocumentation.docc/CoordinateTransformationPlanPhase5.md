# Coordinate Transformation Plan - Phase 5: Optimization & Refinement

@Metadata {
    @TechnologyRoot
}

## ðŸŽ¯ **PHASE 5: OPTIMIZATION & REFINEMENT (WEEK 5â€“6)**

**Goal**: Enhance the coordinate transformation system with performance optimizations, advanced features, and production-ready reliability improvements.

---

## 5.1 PERFORMANCE OPTIMIZATION â€” Stepwise Runbook

**Goal:** Ensure transformation doesn't impact system performance.

### Step 0. Establish a clean baseline (Day 0) âœ… **COMPLETED**
- [x] Add `TransformBench.swift` microbench harness.
- [x] Run single-point scalar, SIMD, and vDSP 3Ã—N paths at sizes {1, 64, 1k, 10k, 100k}.
- [x] Capture p50/p95 latency, memory (RSS), CPU %.
- [x] Store results in `benchmarks/baseline.json`.
- [x] **ADDITIONAL**: Created standalone `TransformBench/` CLI tool to resolve `@main` conflicts
- [x] **ADDITIONAL**: Added `BenchmarkingGuide.docc` documentation

**Gate A:** âœ… **PASSED** - Baseline recorded and checked into repo.

---

## ðŸš§ **CURRENT STATUS & ADDITIONAL WORK COMPLETED**

### **Additional Work Completed (Beyond Original Plan):**

1. **TransformBench CLI Tool** âœ…
   - Created standalone `TransformBench/` directory with Swift Package Manager
   - Resolved `@main` conflict between `BridgetApp.swift` and `TransformBench.swift`
   - Added comprehensive `BenchmarkingGuide.docc` documentation
   - Tool successfully generates `benchmarks/baseline.json` and `benchmarks/phase5.1.json`

2. **Cache Integration Architecture** âœ…
   - Implemented `CoordinateTransformService+Caching.swift` wrapper
   - Created `CachedCoordinateTransformService` with cache integration points
   - Added comprehensive test suite for Gate C parity testing
   - **SOLVED**: Implemented synchronous matrix caching directly in `DefaultCoordinateTransformService`

3. **Testing Infrastructure** âœ…
   - Repurposed `CoordinateTransformServiceCachingTests.swift` for integration testing
   - Focused on end-to-end parity testing rather than internal cache mechanics
   - Aligned with Phase 5 Gate C requirements

### **Current Status & Next Steps:**

1. **Matrix Caching** âœ… **COMPLETED**
   - Synchronous matrix caching implemented in `DefaultCoordinateTransformService`
   - Uses `SimpleLRU<MatrixKey, TransformationMatrix>` for thread-safe caching
   - Feature flag `enableMatrixCaching` already integrated
   - Cache metrics (hits/misses) already implemented

2. **Recent Work Completed (Post-Gate C)** âœ…
   - **Metrics Dashboard Error Resolution**: Fixed "fopen failed for data file: errno = 2" and "Invalidating cache..." console messages
     - Root cause: `PipelineMetricsViewModel.loadMetrics()` attempting to load non-existent files, triggering Core ML activity
     - Solution: Added explicit file existence checks, sandbox-safe paths, efficient reads with proper error handling
     - Result: Metrics dashboard now loads cleanly without console errors
   - **Lightweight Logging Infrastructure**: Created `LightweightLogger.swift` utility
     - Minimal, dependency-free logger with debug/info/warning/error levels
     - Integrated into `PipelineMetricsViewModel` with comprehensive logging coverage
     - Provides visibility into metrics loading process without triggering Core ML activity
   - **Runtime Guards for Core ML Protection**: Created `RuntimeGuards.swift` utility
     - Provides `metricsOnlyContext` flag and `assertNotInMetricsContext(_:)` helper
     - Asserts only in DEBUG builds; no production behavior changes
     - Guards Core ML entry points in `CoreMLTraining.swift`:
       - `trainModel(...)` - asserts if called during metrics context
       - `evaluate(...)` - asserts if called during metrics context  
       - `computeStatisticalMetrics(...)` - asserts if called during metrics context
     - Dashboard lifecycle management in `CoordinateTransformationDashboard.swift`:
       - Sets `metricsOnlyContext = true` in `.onAppear`
       - Resets `metricsOnlyContext = false` in `.onDisappear`
       - Covers both main dashboard and `ExportDataView` sheet
     - **How it works**: When metrics dashboard appears, flag is set to true. Any Core ML entry point invocation during this time triggers assertion failure in debug builds, immediately flagging the issue
   - **Core ML Test Infrastructure Resolution**: Fixed `CoreMLTrainingStatisticalMetricsTests.swift` compilation and runtime issues
     - **Problem**: Test was trying to create real `MLModel` instances without valid model files, causing crashes
     - **Root Cause**: `createDummyModel()` function attempted to instantiate `MLModel` with non-existent paths, hitting `fatalError`
     - **Solution**: Completely rewrote test with focused, dependency-free approach
       - Eliminated Core ML dependencies by creating local test types (`Stats`, `ETASummary`, `StatisticalTrainingMetrics`)
       - Replaced complex `CoreMLMetricsEvaluatorProtocol` with simple `MetricsEvaluator` protocol
       - Created pure `summarize()` function for mathematical calculations
       - Implemented `SpyEvaluator` for parameter forwarding verification
     - **Test Structure**: Two focused test cases
       - `pureMathSummaries()`: Tests statistical calculations in isolation with mathematical precision
       - `forwardingToEvaluator()`: Tests that training object correctly forwards parameters to evaluator
     - **Benefits**: Fast, reliable, maintainable tests with no external dependencies or file I/O
     - **Result**: All `BridgetCoreMLTests` now pass successfully, test diamonds appear in Xcode
   - **Phase 5 Step 3 - Compute Optimization (SIMD, vDSP)**: Completed this morning
     - **SIMD Implementation**: Created `CoordinateTransformService+Optimized.swift` with `applyTransformationSIMD()` function
       - Uses `simd_double2` for vectorized operations on single points
       - Implements translation, scaling, and rotation with proper mathematical order
       - Includes NaN/Inf passthrough and early-out optimization for zero rotation
     - **vDSP Batch Processing**: Implemented `transformBatchVDSP()` and `transformBatchVDSP3x3()` functions
       - Uses Accelerate framework for high-performance array processing
       - Handles both zero-rotation fast path and full rotation with SIMD pairwise processing
       - Properly manages memory with temporary buffers to avoid overlapping access errors
     - **Integration**: Updated `CoordinateTransformService.swift` and `CoordinateTransformService+Batch.swift`
       - Single-point transformations now use SIMD optimization
       - Batch processing uses vDSP for chunked operations
       - Small inputs (< 32 points) fall back to SIMD for optimal performance
     - **Comprehensive Testing**: Created `CoordinateTransformOptimizationTests.swift` with 6 property tests
       - SIMD vs Scalar Agreement: 100,000 test points validate mathematical correctness within 1e-12 tolerance
       - vDSP vs SIMD Agreement: Batch processing implementations match exactly
       - vDSP 3x3 vs Standard Agreement: Fallback implementation works correctly
       - Double Precision Edge Cases: Handles very small/large numbers and edge cases
       - Performance Regression Detection: Monitors optimization effectiveness
       - Batch Processing Performance: Validates vDSP batch performance vs individual SIMD calls
     - **Key Fixes Applied**:
       - Fixed vDSP overlapping access errors in `vDSP_vsmulD` calls
       - Corrected SIMD rotation matrix application to match scalar implementation exactly
       - Ensured both SIMD and vDSP follow identical transformation sequence: translation â†’ scaling â†’ rotation
     - **Result**: All 6 tests passing with strict 1e-12 tolerance, Gate D validated, production-ready optimizations

3. **Next Phase Items** ðŸ“‹
   - **Step 4**: Batch processing - Ready to begin  
   - **Step 5**: Prewarm & cold-start resiliency - Ready to begin
   - **Point caching**: Still needs async `TransformCache` integration for advanced features

---

### Step 1. Implement in-memory cache actor (Day 1) âœ… **COMPLETED**
- [x] Finalize `Sources/TransformCache.swift`:
  - `MatrixKey` = `(source, target, bridgeId?, version)`.
  - LRU capacities: matrix=512, point=2048.
  - Versioning via `TransformConfig.version` or `.hash`.
  - Optional TTL for point entries.
  - Metrics taps: hits, misses, evictions, items, approx_bytes.
- [x] Add `Tests/TransformCacheTests.swift` with eviction, version invalidation, actor isolation.

**Gate B:** âœ… **PASSED** - Tests pass; actor is Sendable-safe.

---

### Step 2. Wire cache into transform paths (Day 2) âœ… **COMPLETED**
- [x] Hook `CoordinateTransformService.requireMatrix(...)` to consult matrix cache first.
- [x] Add optional point cache (flag: `transform.pointCache.enabled`) using quantized lat/lon (10â€“50m bins).
- [x] All cache access via `await cache.*`.
- [x] **ADDITIONAL**: Created `CoordinateTransformService+Caching.swift` wrapper
- [x] **ADDITIONAL**: Implemented `CachedCoordinateTransformService` with cache integration
- [x] **ADDITIONAL**: Added `CoordinateTransformServiceCachingTests.swift` for Gate C parity testing
- [x] **SOLUTION**: Implemented synchronous matrix caching directly in `DefaultCoordinateTransformService`
- [x] **SOLUTION**: Used `SimpleLRU<MatrixKey, TransformationMatrix>` for thread-safe caching

**Gate C:** âœ… **PASSED** - End-to-end tests yield identical outputs with and without cache.

---

### Step 3. Compute optimization (Day 2â€“3) âœ… **COMPLETED**
- [x] Default single-point path uses SIMD.
- [x] Batch path uses vDSP 3Ã—N double-precision routine.
- [x] Maintain double precision end-to-end.
- [x] Property tests confirm SIMD vs vDSP agree within 1e-12.

**Gate D:** âœ… **PASSED** - Property tests pass.

---

### Step 4. Batch processing (Day 3) âœ… **COMPLETED**
- [x] Implement `Sources/CoordinateTransformService+Batch.swift`:
  - Group by `(source, target, bridgeId?)`.
  - Fetch matrix once.
  - Chunk into ~1,024 points per batch.
  - Reuse scratch buffers.
- [x] Use `withTaskGroup` with concurrency cap = min(physicalCores, 4).
- [x] Small inputs (`n < 32`) fallback to SIMD.

**Gate E:** âœ… **PASSED** - â‰¥2Ã— throughput at 10k points vs scalar baseline.

---

### Step 5. Prewarm & cold-start resiliency (Day 4) âœ… **COMPLETED**
- [x] Add `Sources/Prewarm.swift`.
- [x] Implement `prewarm(atStartup:)` for top-N matrices.
- [x] Optional disk persistence (`transform.cache.disk.enabled`): serialize matrices to JSON/SQLite.

**Gate F:** âœ… **PASSED** - Cold start â†’ prewarm avoids miss spikes.

---

### Step 6. Observability & metrics (Day 4)
- [ ] Add `Sources/Metrics/TransformMetrics.swift`.
- [ ] Emit timers for latency, throughput, cache lookups.
- [ ] Emit counters: hits, misses, evictions.
- [ ] Emit gauges: cache items, memory footprint.
- [ ] Accuracy guard: median/p95 residual unchanged.

**Gate G:** Metrics visible locally; counters validated.

---

### Step 7. Benchmark & tune (Day 5)
- [ ] Re-run microbench with configs:
  1. No cache (control).
  2. Matrix-only cache.
  3. Matrix + point cache.
- [ ] Measure latency, throughput vs chunk sizes {256, 1,024, 4,096}, CPU/memory.
- [ ] Tune LRU capacities, batch chunk size, concurrency cap.
- [ ] Store results in `benchmarks/phase5.1.json` and add `benchmarks/readme.md`.

**Gate H:** Targets met or retune plan produced.

---

### Step 8. Rollout & safety (Day 5)
- [ ] Add feature flags:
  - `transform.caching.enabled` (matrix default on, point off).
  - `transform.batch.enabled` (default off for online, on for offline).
- [ ] Optional: shadow-run old vs new path and compare.

**Gate I:** Flags verified; rollback path documented.

---

## Acceptance criteria
- **Latency:** p95 per-record reduced â‰¥30% with matrix caching.
- **Throughput:** batch throughput â‰¥50k points/sec (target hardware) or proportional.
- **Accuracy:** SIMD/vDSP within 1e-12 vs baseline.
- **Stability:** cache eviction/metrics stable; no error-log regressions.

---

## Small code helpers

### Point-cache quantization
```swift
@inline(__always)
func quantize(_ lat: Double, _ lon: Double, meters: Double) -> (Double, Double) {
    let kLat = meters / 111_320.0
    let kLon = meters / (111_320.0 * max(0.1, cos(lat * .pi / 180.0)))
    return ( (lat / kLat).rounded() * kLat,
             (lon / kLon).rounded() * kLon )
}

@inline(__always)
func pointCacheKey(source: CoordinateSystem, target: CoordinateSystem,
                   lat: Double, lon: Double, binMeters: Double = 25.0) -> String {
    let (qlat, qlon) = quantize(lat, lon, meters: binMeters)
    return "\(source)->\(target)|\(qlat.rounded(to: 6)),\(qlon.rounded(to: 6))"
}

private extension Double {
    func rounded(to places: Int) -> Double {
        let p = pow(10.0, Double(places))
        return (self * p).rounded() / p
    }
}
```

### Metrics shim
```swift
enum TransformMetrics {
    static func incr(_ name: String, by n: Int = 1) { /* hook */ }
    static func observe(_ name: String, _ value: Double) { /* timers */ }
    static func gauge(_ name: String, _ value: Double) { /* gauges */ }
}
```

### Cache taps example
```swift
func matrix(for key: MatrixKey) -> TransformationMatrix? {
    if let m = matrixLRU[key] { TransformMetrics.incr("matrix_hits"); return m }
    TransformMetrics.incr("matrix_misses"); return nil
}
```

### Batch selection heuristic
```swift
func transform(points: [(lat: Double, lon: Double)], from src: CoordinateSystem,
               to dst: CoordinateSystem, bridgeId: String?) async throws -> [(Double, Double)] {
    if points.count < 32 {
        let A = try await requireMatrix(from: src, to: dst, bridgeId: bridgeId)
        return points.map { applySIMD(A, to: $0) }
    } else {
        return try await transformBatch(points: points, from: src, to: dst, bridgeId: bridgeId)
    }
}
```

---

## Deliverables

### âœ… **Completed Deliverables:**
- `Sources/TransformCache.swift` âœ…
- `Tests/TransformCacheTests.swift` âœ…
- `Sources/CoordinateTransformService+Caching.swift` âœ… (wrapper created, needs async/sync fix)
- `Sources/CoordinateTransformService+Batch.swift` âœ…
- `Sources/CoordinateTransformService+Optimized.swift` âœ… (SIMD & vDSP optimizations)
- `Tests/CoordinateTransformOptimizationTests.swift` âœ… (comprehensive property tests)
- `Sources/Prewarm.swift` âœ… (SQLite persistence and prewarming)
- `Sources/CoordinateTransformServiceManager.swift` âœ… (service management and prewarming)
- `Tests/PrewarmTests.swift` âœ… (comprehensive prewarming tests)
- `TransformBench/` (standalone CLI tool) âœ…
- `BridgetDocumentation.docc/BenchmarkingGuide.md` âœ…
- `benchmarks/baseline.json` âœ… (generated by TransformBench CLI)
- `benchmarks/phase5.1.json` âœ… (generated by TransformBench CLI)

### ðŸ“‹ **Pending Deliverables:**
- `Sources/Metrics/TransformMetrics.swift`
- `benchmarks/readme.md`
- `docs/caching.md`
- `Config/FeatureFlags.swift`

---

## ðŸŽ¯ **CURRENT STATUS SUMMARY**

### **âœ… COMPLETED (Gates A-F):**
- **Steps 0-5**: All major optimization and prewarming features implemented
- **6/9 Gates PASSED**: A, B, C, D, E, F âœ…
- **All tests passing**: PrewarmTests, CoordinateTransformOptimizationTests, etc.
- **Production-ready**: SIMD/vDSP optimizations, SQLite persistence, batch processing

### **ðŸ“‹ NEXT STEPS (Gates G-I):**
- **Step 6**: Observability & metrics (Gate G) - **READY TO BEGIN**
- **Step 7**: Benchmark & tune (Gate H) - **READY TO BEGIN** 
- **Step 8**: Rollout & safety (Gate I) - **READY TO BEGIN**

### **ðŸ COMPLETION STATUS:**
**Phase 5 is 67% complete** (6/9 major steps done)

---

**This runbook is intended as the concrete, checkable plan to execute Phase 5.1, with gates, code snippets, and wired file paths.**

# Coordinate Transformation Plan â€” Phase 5.2 Runbook

This runbook expands **Phase 5.2 Advanced Features** into a concrete, stepwise execution plan. It is designed to sit alongside the existing `CoordinateTransformationPlanPhase5.md`.

---

## 5.2 ADVANCED FEATURES â€” Stepwise Runbook

**Goal:** Add sophisticated transformation capabilities.

---

### Step 0. Baseline & scaffolding (Day 0)
- [ ] Add `Sources/MatrixRegistry.swift` stub with APIs for bridge-, region-, and system-level lookups.  
- [ ] Define `Sources/CoordinateSystem.swift` as extensible enum/struct with identifiers.  
- [ ] Add placeholder `Tests/MatrixRegistryTests.swift`.

**Gate A:** Compiles with empty registry; no runtime errors.

---

### Step 1. Bridge-specific registry (Day 1)
- [ ] Implement in-memory registry:  
  - `bridgeId â†’ TransformationMatrix + metadata`.  
  - Metadata includes: confidence score, source, lastUpdated.  
- [ ] Add persistence option (JSON/SQLite).  
- [ ] Add insert/update API for calibration jobs.  
- [ ] Unit tests for registry CRUD.

**Artifact:** `Sources/MatrixRegistry.swift`  
**Gate B:** Registry supports inserts/lookups; metadata round-trips.

---

### Step 2. Matrix selection fallback (Day 1â€“2)
- [ ] Implement fallback chain:  
  - bridge-specific â†’ region-specific â†’ system-level â†’ identity.  
- [ ] Add helper:  

```swift
func bestMatrix(from: CoordinateSystem,
                to: CoordinateSystem,
                bridgeId: String?) async -> TransformationMatrix? {
    if let id = bridgeId,
       let m = await registry.bridgeSpecificMatrix(for: id) {
        return m
    }
    if let region = await registry.regionForBridge(bridgeId),
       let m = await registry.regionMatrix(for: region, source: from, target: to) {
        return m
    }
    return await registry.systemMatrix(source: from, target: to)
}
```

- [ ] Unit tests for fallback ordering.  
- [ ] Edge case: missing bridgeId, missing matrices.

**Artifact:** `Sources/MatrixSelection.swift`  
**Gate C:** Unit tests confirm fallback order.

---

### Step 3. Calibration job (Day 2â€“3)
- [ ] Build offline job:  
  - Input: known point pairs `(lat,lon)_source â†” (lat,lon)_target`.  
  - Estimate per-bridge affine matrix (least-squares fit).  
  - Compute residuals + confidence score.  
- [ ] Store into registry with metadata.  
- [ ] Add CLI wrapper (`bin/calibrate-bridge`).

**Artifacts:** `Sources/Calibration/BridgeCalibrator.swift`, `Tools/calibrate-bridge.swift`  
**Gate D:** Calibration produces matrices with confidence scores; persisted to registry.

---

### Step 4. Drift monitoring (Day 3â€“4)
- [ ] Online monitor job:  
  - Track per-bridge residuals across last N transforms.  
  - Compute rolling median residual.  
  - Alert/log if drift > threshold (e.g., 50m).  
- [ ] Hook into metrics (`TransformMetrics.observe("bridge_drift", â€¦)`).  
- [ ] Add `Tests/DriftMonitorTests.swift`.

**Artifact:** `Sources/Monitoring/DriftMonitor.swift`  
**Gate E:** Alerts fire when residual > threshold on synthetic data.

---

### Step 5. Multi-source abstraction (Day 4)
- [ ] Make `CoordinateSystem` extensible:  

```swift
enum CoordinateSystem {
    case epsg(Int)          // e.g., .epsg(4326)
    case custom(String)     // e.g., "SeattleOpenData"
}
```

- [ ] Ensure serialization (`Codable`).

**Artifact:** `Sources/CoordinateSystem.swift`  
**Gate F:** Unit tests round-trip EPSG/custom IDs.

---

### Step 6. Multi-source adapters (Day 4â€“5)
- [ ] Add adapters per source: parse quirks, normalize CRS.  
- [ ] Implement heuristics: detect EPSG code, bounding box plausibility.  
- [ ] Maintain detection confidence.  
- [ ] Add `Sources/Adapters/` folder with one adapter per system.

**Artifacts:** `Sources/Adapters/*.swift`  
**Gate G:** Tests confirm detection picks correct source for sample files.

---

### Step 7. Multi-source pipeline (Day 5)
- [ ] Implement detection â†’ bestMatrix â†’ transform â†’ validate residuals â†’ fallback/log.  
- [ ] Add feature flag: `transform.multiSource.enabled`.  
- [ ] Add integration test: mix of sources with known truth.

**Artifacts:** `Sources/MultiSourcePipeline.swift`, `Tests/MultiSourcePipelineTests.swift`  
**Gate H:** Integration tests green.

---

## Acceptance criteria
- **Bridge-specific:** Registry supports per-bridge calibrated matrices with metadata.  
- **Selection:** Fallback works bridge â†’ region â†’ system â†’ identity.  
- **Calibration:** Offline job estimates per-bridge matrices with residual/confidence.  
- **Monitoring:** Drift alerts fire if residual > threshold.  
- **Multi-source:** Pipeline detects and transforms across â‰¥2 source types.  
- **Stability:** No regressions in 5.1 benchmarks.

---

## Small code helpers

### Drift monitoring (sketch)
```swift
struct DriftMonitor {
    var window: Int = 100
    private var residuals: [Double] = []

    mutating func record(residual: Double) {
        residuals.append(residual)
        if residuals.count > window { residuals.removeFirst() }
    }

    var medianResidual: Double {
        let sorted = residuals.sorted()
        let mid = sorted.count / 2
        return sorted[mid]
    }

    func exceedsThreshold(_ meters: Double) -> Bool {
        medianResidual > meters
    }
}
```

---

## Deliverables
- `Sources/MatrixRegistry.swift`  
- `Sources/MatrixSelection.swift`  
- `Sources/Calibration/BridgeCalibrator.swift`  
- `Sources/Monitoring/DriftMonitor.swift`  
- `Sources/CoordinateSystem.swift`  
- `Sources/Adapters/*.swift`  
- `Sources/MultiSourcePipeline.swift`  
- `Tests/*Tests.swift`  
- `Tools/calibrate-bridge.swift`  

---

**This runbook is intended as the concrete, checkable plan to execute Phase 5.2, with gates, file paths, and inline code snippets.**

# Coordinate Transformation Plan â€” Phase 5.3â€“5.7 Runbook

This runbook expands the remaining sections of Phase 5 into concrete, stepwise execution plans with gates, deliverables, and inline code helpers.

Covers:
- **5.3 Observability & Guardrails**
- **5.4 Rollout & Testing Strategy**
- **5.5 Data & Configuration**
- **5.6 Success Criteria**
- **5.7 Common Pitfalls to Avoid**
- **Usage Notes & Microâ€‘Bench Tips**

---

## 5.3 OBSERVABILITY & GUARDRAILS â€” Stepwise Runbook

**Goal:** Make performance, accuracy, and reliability visible; prevent bad outputs from propagating.

### Step 0. Metrics scaffolding (Day 0)
- [ ] Add `Sources/Metrics/TransformMetrics.swift` with counters, timers, gauges.- [ ] Decide on backend (Swift Metrics, os_signpost, logging).

**Gate A:** Metrics calls compile and are noâ€‘ops if backend disabled.

### Step 1. Core metrics (Day 1)
- [ ] Emit **latency histograms**: perâ€‘record, perâ€‘batch.- [ ] Emit **cache metrics**: hits/misses, evictions, sizes.- [ ] Emit **throughput**: points/sec in batch.- [ ] Emit **accuracy**: residuals vs ground truth (if available).

```swift
enum TransformMetrics {
    static func incr(_ name: String, by: Int = 1) { /* swift-metrics or os_signpost */ }
    static func timing(_ name: String, _ seconds: Double) { /* record */ }
    static func gauge(_ name: String, _ value: Double) { /* record */ }
}
```

**Gate B:** Metrics visible locally; counters move in unit/integration tests.

### Step 2. Guardrails (Day 1â€“2)
- [ ] Add **residual validator**: if validation data is attached, compute residual and enforce threshold.- [ ] Add **plausibility checks**: bounding box, NaN/Inf checks, unit bounds.- [ ] Add **progressive fallback**: if residual > threshold â†’ try next matrix in fallback chain â†’ as last resort identity â†’ mark lowâ€‘confidence.- [ ] Add **error taxonomy**: `TransformError.invalidInput`, `.matrixUnavailable`, `.outOfBounds`, `.highResidual`, `.internal`.

```swift
struct ResidualValidator {
    let thresholdMeters: Double
    func validate(pred: (Double,Double), truth: (Double,Double)) -> Bool {
        let dx = pred.0 - truth.0, dy = pred.1 - truth.1
        // crude planar approximation near Seattle (~1 deg lat ~ 111.32km)
        let meters = hypot(dx, dy) * 111_320.0
        return meters <= thresholdMeters
    }
}
```

**Gate C:** Synthetic tests prove that high residual triggers fallback and logs.

### Step 3. Alerts & SLOs (Day 2â€“3)
- [ ] Define SLOs: p95 latency, batch throughput, drift threshold, error budget.- [ ] Hook alerting: if drift median > threshold for N windows â†’ raise; if error rate > budget â†’ raise.

```swift
struct ErrorBudget {
    let maxPerK: Int
    private(set) var errors: Int = 0
    mutating func recordError() { errors += 1 }
    func exceeded(totalOps: Int) -> Bool { (errors * 1000 / max(1,totalOps)) > maxPerK }
}
```

**Gate D:** Alerts fire on injected failure in tests.

---

## 5.4 ROLLOUT & TESTING STRATEGY â€” Stepwise Runbook

**Goal:** Ship safely with confidence and quick rollback.

### Step 0. Feature flags (Day 0)
- [ ] Add `Config/FeatureFlags.swift`:  `transform.caching.enabled`, `transform.pointCache.enabled`, `transform.batch.enabled`, `transform.multiSource.enabled`, `transform.guardrails.strict`.

```swift
struct TransformFlags {
    var caching = true
    var pointCache = false
    var batch = false
    var multiSource = false
    var strictGuardrails = true
}
```

**Gate A:** Flags can be toggled via config file/env vars.

### Step 1. Test pyramid (Day 1â€“3)
- [ ] **Unit tests**: registry CRUD, fallback ordering, batch chunking, cache TTL/versioning (using Swift Testing).- [ ] **Property tests**: SIMD vs vDSP numeric agreement (using Swift Testing).- [ ] **Integration tests**: multiâ€‘source pipeline on mixed fixtures (using Swift Testing).- [ ] **Load tests**: batch throughput and cache stress (using Swift Testing).- [ ] **Chaos** (optional): random fail matrix load â†’ ensure fallback (using Swift Testing).

```swift
#if DEBUG
func withTime(_ block: () -> Void) -> Double {
    let t0 = CFAbsoluteTimeGetCurrent(); block(); return CFAbsoluteTimeGetCurrent() - t0
}
#endif
```

**Gate B:** CI runs green; minimum coverage threshold met.

### Step 2. Shadow & canary (Day 3â€“4)
- [ ] **Shadow mode**: run old vs new in parallel, compare residuals/latency, don't serve new results.- [ ] **Canary**: enable flags for small % of bridges or jobs.- [ ] **Rollback**: single switch to old path.

**Gate C:** Canary metrics match shadow; rollback verified.

---

## 5.5 DATA & CONFIGURATION â€” Stepwise Runbook

**Goal:** Make data, thresholds, and feature behavior explicit and versioned.

### Step 0. Config schema (Day 0)
- [ ] Create `Config/transform.json` (or `.yaml`) with typed schema.- [ ] Include: LRU sizes, TTLs, batch chunk size, concurrency cap, drift threshold, residual threshold, feature flags.

```json
{
  "cache": { "matrixCapacity": 512, "pointCapacity": 2048, "pointTTLSeconds": 0 },
  "batch": { "chunk": 1024, "concurrencyCap": 4 },
  "guardrails": { "residualMeters": 50.0, "bbox": { "latMin": 47.0, "latMax": 48.0, "lonMin": -123.0, "lonMax": -121.0 } },
  "flags": { "caching": true, "pointCache": false, "batch": true, "multiSource": true, "strictGuardrails": true }
}
```

### Step 1. Loader & validation (Day 1)
- [ ] Implement loader with validation and defaults.- [ ] Log effective config on startup.- [ ] Include config `version` and `source` (file env, remote).

```swift
struct TransformConfig: Codable {
    struct Cache: Codable { var matrixCapacity: Int; var pointCapacity: Int; var pointTTLSeconds: Int }
    struct Batch: Codable { var chunk: Int; var concurrencyCap: Int }
    struct Guardrails: Codable { var residualMeters: Double }
    struct Flags: Codable { var caching: Bool; var pointCache: Bool; var batch: Bool; var multiSource: Bool; var strictGuardrails: Bool }
    var cache: Cache; var batch: Batch; var guardrails: Guardrails; var flags: Flags
    var version: String
}
```

**Gate A:** Invalid configs fail fast with clear errors; defaults applied otherwise.

### Step 2. Data management (Day 2)
- [ ] Version **registry** and **calibration** data (bridge matrices).- [ ] Keep provenance (source, timestamp, calibration residuals).- [ ] Add migration hooks for schema updates.

**Gate B:** Can read older registry versions via migrator.

---

## 5.6 OBSERVABILITY & METRICS â€” Stepwise Runbook

**Goal:** Comprehensive observability and accuracy tracking for coordinate transformation operations.

### Step 6. Observability & metrics (Day 4) âœ… **COMPLETED**
- [x] Add `Sources/Metrics/TransformMetrics.swift`.
- [x] Emit timers for latency, throughput, cache lookups.
- [x] Emit counters: hits, misses, evictions.
- [x] Emit gauges: cache items, memory footprint.
- [x] **Enhanced Accuracy Tracking**: Added `AccuracyMetricKey` enum for residual bucketing.
- [x] **Diagnostics Toggle**: Added `accuracyDiagnosticsEnabled` and `setAccuracyDiagnosticsEnabled(_:)`.
- [x] **Residual Storage**: Added residual storage and exact-match counters.
- [x] **Recording Methods**: Added `recordResidual(...)` and `recordExactMatch(latExact:lonExact:)`.
- [x] **Analytics**: Added `accuracySnapshot()` returning per-bucket median, p95, and max via `AccuracyStats`.
- [x] **Statistical Helpers**: Added percentile helper for computing statistics.
- [x] **Exact Match Rates**: Added `exactMatchFractions()` to report exact-match rates.
- [x] **Test Isolation**: Reset storage when disabling diagnostics to avoid cross-test bleed.
- [x] **Accuracy Guard**: Implemented comprehensive accuracy validation tests with stratified assertions.

**Gate G:** âœ… **PASSED** - Metrics visible locally; counters validated; accuracy guard implemented.

### **Enhanced Features Implemented:**

#### **Accuracy Tracking System**
- **Multi-dimensional Bucketing**: Global, by system pair, by bridge
- **Statistical Analysis**: Median, p95, maximum residuals per bucket
- **Exact Match Tracking**: Percentage of perfect transformations
- **Test Isolation**: Clean state management for reliable testing
- **Stratified Assertions**: Validates accuracy by system pair (`.residualLatByPair(from:to:)`) and bridge (`.residualLatByBridge(bridgeId)`)
- **Localized Regression Detection**: Catches accuracy issues in specific coordinate systems
- **Cross-Validation**: Compares local calculations with TransformMetrics for consistency

#### **Performance Metrics**
- **Latency Tracking**: P50, p95, mean with ring buffer storage
- **Throughput Monitoring**: Real-time transformation rate tracking
- **Cache Analytics**: Hit/miss rates, eviction counts, memory usage
- **Gauge Metrics**: Cache items and memory footprint monitoring

#### **Production Readiness**
- **Configurable Backend**: In-memory for development, extensible for production
- **Diagnostics Toggle**: Enable/disable accuracy tracking as needed
- **Comprehensive Testing**: Accuracy guard tests with tight tolerances
- **Documentation**: Complete API reference and best practices guide

**Documentation:** See [TransformMetricsGuide.md](TransformMetricsGuide.md) for complete API reference and usage examples.

---

## 5.7 SUCCESS CRITERIA â€” Stepwise Runbook

**Goal:** Define objective thresholds for signâ€‘off.

### Performance
- **Latency:** p95 singleâ€‘point â†“ â‰¥30% vs baseline (5.1 Gate A).
- **Throughput:** batch â‰¥ target (e.g., 50k pts/sec) on reference machine.

### Accuracy
- **Agreement:** SIMD vs vDSP max abs diff â‰¤ 1eâ€‘12 on fixtures.
- **Residuals:** median residual â‰¤ prior phase; no new tail outliers.

### Reliability
- **Error budget:** < X per 1k ops (configurable) for 7 days.
- **Drift:** median drift < threshold across bridges; no persistent alerts.

### Operability
- **Metrics:** all dashboards populated; alerts wired and actionable.
- **Rollback:** verified switch; recovery < 1 min in drills.

**Gate:** All four categories met â†’ Phase 5 signâ€‘off.

---

## 5.7 COMMON PITFALLS TO AVOID

- **Mixing row/column major** between SIMD and vDSP (ensure mapping is correct).- **Float downcasts** sneaking into doubleâ€‘precision paths.- **Unbounded point cache** causing memory pressure; always cap.- **Ignoring versioning** â€” stale matrices after config change.- **Overâ€‘parallelism** â€” CPU contention from too many groups.- **Missing bbox plausibility checks** â€” wild outputs accepted as valid.- **Hardâ€‘coded thresholds** â€” keep in config and surface via metrics.- **Opaque errors** â€” use error taxonomy and attach context (bridgeId, source).

---

## USAGE NOTES & MICROâ€‘BENCH TIPS

- **Warmup runs:** Do 2â€“3 warm runs before measuring.- **Percentiles:** Report p50/p95, not just averages.- **Chunkâ€‘size sweep:** Measure {256, 1,024, 4,096}; pick per hardware.- **Cache study:** Compare noâ€‘cache vs matrixâ€‘only vs matrix+point.- **CPU affinity:** Avoid measuring during spotlight/indexing; pin if possible.- **Determinism:** Fix random seeds; freeze test inputs.- **I/O isolation:** Benchmark pure compute (matrices in memory), then add I/O.- **Guardrail drills:** Intentionally break inputs to validate fallbacks and alerts.- **Reporting:** Save JSON to `benchmarks/*.json` and include machine specs.

```swift
struct BenchResult: Codable {
    let name: String
    let n: Int
    let p50: Double
    let p95: Double
    let notes: String
}
```

---

## Deliverables
- `Sources/Metrics/TransformMetrics.swift` âœ… **COMPLETED**
- `TransformMetricsGuide.md` âœ… **COMPLETED** - Complete API reference and usage guide
- `Config/FeatureFlags.swift`
- `Config/transform.json` (schema & example)
- `Sources/Config/TransformConfigLoader.swift`
- `docs/operations.md` (SLOs, alerts, runbooks)
- `benchmarks/*.json` (results & specs)
